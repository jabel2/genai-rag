version: '3'
services:
  python:
    build: .
    networks:
      - mynetwork
    volumes:
      - .:/app
    working_dir: /app
    ports:
      - "8501:8501"
    command: tail -f /dev/null

  neo4j:
    image: neo4j:latest
    networks:
      - mynetwork
    ports:
      - "7474:7474"
      - "7687:7687"
    volumes:
      - ./neo4j/data:/var/lib/neo4j/data
      - ./neo4j/import:/var/lib/neo4j/import
      - ./neo4j/plugins:/var/lib/neo4j/plugins
      - ./neo4j/licenses:/var/lib/neo4j/licesnses
    environment:
      - name=neo4j
      - NEO4J_AUTH=neo4j/neo4juser
      - NEO4J_ACCEPT_LICENSE_AGREEMENT=yes
      - NEO4J_dbms_memory_pagecache_size=4G
      - NEO4J_server_memory_heap_max__size=4G
      - NEO4J_PLUGINS=[\"graph-data-science\",\"apoc\",\"bloom\"]
      - NEO4J_dbms_security_procedures_unrestricted="gds.*"
      - NEO4J_dbms_security_procedures_unrestricted="bloom.*"
      - NEO4J_dbms_security_procedures_unrestricted="apoc.*"
      - NEO4J_apoc_export_file_enabled=true
      - NEO4J_apoc_import_file_enabled=true
      - NEO4J_apoc_import_file_use__neo4j__config=true
      - NEO4J_DEBUG=yes

  llama-cpp-python:
    image: ghcr.io/abetlen/llama-cpp-python:latest
    networks:
      - mynetwork
    ports:
      - "8000:8000"
    volumes:
      - ./models:/models
    environment:
      - MODEL=/models/llama-2-13b-chat.Q6_K.gguf

networks:
  mynetwork: